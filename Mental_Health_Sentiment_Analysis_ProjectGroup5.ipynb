{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChandramouliSridharan/Mental-Health-Sentiment-Analysis-using-Deep-Learning./blob/main/Mental_Health_Sentiment_Analysis_ProjectGroup5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9382c76",
      "metadata": {
        "id": "a9382c76"
      },
      "source": [
        "**Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bxzQ9ayLeBti",
      "metadata": {
        "id": "bxzQ9ayLeBti"
      },
      "outputs": [],
      "source": [
        "# ! pip install tensorfloW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ZUMPLIkGV91",
      "metadata": {
        "collapsed": true,
        "id": "6ZUMPLIkGV91"
      },
      "outputs": [],
      "source": [
        "# Install this package Initially for the BERT model to run.\n",
        "!pip install tensorflow==2.15.0 tensorflow-text==2.15.0 tensorflow-hub==0.16.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12297949",
      "metadata": {
        "id": "12297949"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "import re\n",
        "import random\n",
        "from wordcloud import WordCloud\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Flatten, Embedding, Dropout, Input, concatenate, MaxPooling1D, Conv1D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b828745",
      "metadata": {
        "id": "5b828745"
      },
      "outputs": [],
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cf12bb8",
      "metadata": {
        "id": "4cf12bb8"
      },
      "source": [
        "**Reading data from a CSV file**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24b49842",
      "metadata": {
        "id": "24b49842",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Creating a datframe.\n",
        "data = pd.read_csv(\"/content/Combined Data.csv\", index_col = 0)\n",
        "# Displaying 5 random rows from the DataFrame to inspect the data.\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eba35ab1",
      "metadata": {
        "id": "eba35ab1"
      },
      "source": [
        "***Analyzing the data***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23d2512a",
      "metadata": {
        "id": "23d2512a"
      },
      "source": [
        "Checking the dimensions of the DataFrame (number of rows and columns)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f3c79b4",
      "metadata": {
        "id": "4f3c79b4"
      },
      "outputs": [],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a61fe2dc",
      "metadata": {
        "id": "a61fe2dc"
      },
      "source": [
        "Calculate the length of each statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3212d8c",
      "metadata": {
        "id": "e3212d8c"
      },
      "outputs": [],
      "source": [
        "# Calculate the character length of each statement\n",
        "data['char_count'] = data['statement'].str.len()\n",
        "\n",
        "# Display basic statistics of statement lengths\n",
        "print(data['char_count'].describe())\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a8d4aab",
      "metadata": {
        "id": "5a8d4aab"
      },
      "source": [
        "***Visualizing the distribution of the lengths of statements.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50d9279",
      "metadata": {
        "id": "a50d9279"
      },
      "outputs": [],
      "source": [
        "data['char_count'].hist(bins=100, color='skyblue', range=(1,15000))\n",
        "plt.title('Frequency Distribution of Statement Lengths')\n",
        "plt.xlabel('Number of Characters in the Statements')\n",
        "plt.ylabel('Statement Counts')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94bc69b4",
      "metadata": {
        "id": "94bc69b4"
      },
      "source": [
        "Filter the data for statements longer than 5000 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eb6debe",
      "metadata": {
        "id": "1eb6debe"
      },
      "outputs": [],
      "source": [
        "filtered_df = data[data['char_count']>5000]\n",
        "filtered_df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3cee43",
      "metadata": {
        "id": "6e3cee43"
      },
      "source": [
        "Getting the count of statements in each category to understand how diverse the data is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f377c90",
      "metadata": {
        "id": "5f377c90"
      },
      "outputs": [],
      "source": [
        "data['status'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c64e678",
      "metadata": {
        "id": "8c64e678"
      },
      "source": [
        "Visualize the count of statements in each category as a bar graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab3b3c3",
      "metadata": {
        "id": "aab3b3c3"
      },
      "outputs": [],
      "source": [
        "category_count=data['status'].value_counts()\n",
        "category_count.plot(kind='bar', title='Distribution of Sentiments of Different Categories',\n",
        "color='#800000')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f1c4e18",
      "metadata": {
        "id": "6f1c4e18"
      },
      "source": [
        "Creating a pie chart to visualize the distribution of the 'status' column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc0035a2",
      "metadata": {
        "id": "dc0035a2"
      },
      "outputs": [],
      "source": [
        "fig = px.pie(data, names='status',labels='status', title='Mental Health Category Distribution')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3679881e",
      "metadata": {
        "id": "3679881e"
      },
      "source": [
        "**DATA CLEANING AND DATA PRE-PROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2950093c",
      "metadata": {
        "id": "2950093c"
      },
      "source": [
        "Checking whether the null values are present in each column of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e4cf44c",
      "metadata": {
        "id": "5e4cf44c"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc2e0a7b",
      "metadata": {
        "id": "dc2e0a7b"
      },
      "source": [
        "Dropping rows with null values from the DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50904c60",
      "metadata": {
        "id": "50904c60"
      },
      "outputs": [],
      "source": [
        "# removing null values\n",
        "data.dropna(inplace = True)\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0580ac8",
      "metadata": {
        "id": "e0580ac8"
      },
      "source": [
        "Preprocessing the text data by converting statements to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd74e37",
      "metadata": {
        "id": "ebd74e37"
      },
      "outputs": [],
      "source": [
        "data['statement']=data['statement'].str.lower()\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abdefe9d",
      "metadata": {
        "id": "abdefe9d"
      },
      "source": [
        "Cleaning the data of the 'statement' column based on Regex pattern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a764a3d",
      "metadata": {
        "id": "6a764a3d"
      },
      "outputs": [],
      "source": [
        "def remove_expression(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
        "    # Remove markdown-style links\n",
        "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
        "    # Remove handles (that start with '@')\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    # Remove punctuation and other special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply the function to the 'statement' column\n",
        "data['statement'] = data['statement'].apply(remove_expression)\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ed6d02",
      "metadata": {
        "id": "09ed6d02"
      },
      "source": [
        "Tokenizing the statements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801a0739",
      "metadata": {
        "id": "801a0739"
      },
      "outputs": [],
      "source": [
        "# Apply word_tokenize to each element in the 'statement' column(tokenization)\n",
        "data['tokens_list'] = data['statement'].apply(word_tokenize)\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "753b528a",
      "metadata": {
        "id": "753b528a"
      },
      "source": [
        "Removing stopwords and Stemming using Porter stemmer from the tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "135dd083",
      "metadata": {
        "id": "135dd083"
      },
      "outputs": [],
      "source": [
        "# Stemming\n",
        "# Initialize the stemmer\n",
        "stopwords_list = stopwords.words('english')\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to stem tokens and convert them to strings\n",
        "def stem_tokens_list(tokens_list):\n",
        "    return ' '.join(stemmer.stem(str(token)) for token in tokens_list if token not in stopwords_list )\n",
        "\n",
        "# Apply the function to the 'tokens' column\n",
        "data['stemmed_tokens'] = data['tokens_list'].apply(stem_tokens_list)\n",
        "\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a389480",
      "metadata": {
        "id": "1a389480"
      },
      "source": [
        "Creating WordCloud to identify the important and repeated tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4959014c",
      "metadata": {
        "id": "4959014c"
      },
      "outputs": [],
      "source": [
        "# Word Cloud\n",
        "colors = ['#16325B', '#227B94', '#78B7D0', '#FFDC7F', '#18587A', '#11999E', '#283644']\n",
        "\n",
        "# Define a color function that randomly selects colors from the palette\n",
        "def color_function(word, font_size, position, orientation, random_state=101, **kwargs):\n",
        "    return random.choice(colors)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb8d444",
      "metadata": {
        "id": "9cb8d444"
      },
      "source": [
        "Wordcloud for each mental health status category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfc6406",
      "metadata": {
        "id": "bbfc6406"
      },
      "outputs": [],
      "source": [
        "# Get unique categories in 'status'\n",
        "categories  = data['status'].unique()\n",
        "\n",
        "plt.figure(figsize=(12, 36))\n",
        "\n",
        "# Generate and plot the WordCloud for each category\n",
        "for i, category  in enumerate(categories):\n",
        "\n",
        "    # Filter the tokens data for the current status\n",
        "    total_tokens = ' '.join(data[data['status'] == category]['tokens_list'].dropna().apply(lambda tokens: ' '.join(tokens)).tolist())\n",
        "\n",
        "    # Generate the WordCloud\n",
        "    wc = WordCloud(width=800, height=400, background_color='white', color_func=color_function).generate(total_tokens)\n",
        "\n",
        "    # Plot the WordCloud in a subplot\n",
        "    axes = plt.subplot(len(categories) // 2 + 1, 2, i + 1)\n",
        "    plt.imshow(wc, interpolation='bilinear')\n",
        "    plt.title(f'WordCloud for Status: {category}')\n",
        "\n",
        "# Apply tight layout after generating all subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust the vertical spacing between subplots (hspace controls vertical space)\n",
        "plt.subplots_adjust(hspace= -0.8)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14Ccp4_ybBiL",
      "metadata": {
        "id": "14Ccp4_ybBiL"
      },
      "outputs": [],
      "source": [
        "Lb = LabelEncoder()\n",
        "data['status'] = Lb.fit_transform(data['status'])\n",
        "print(data['status'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-yVxUMe7dolQ",
      "metadata": {
        "id": "-yVxUMe7dolQ"
      },
      "outputs": [],
      "source": [
        "row_counts = []\n",
        "\n",
        "for i in range(7):  # For each status from 0 to 6\n",
        "    subset = data[data['status'] == i]\n",
        "    count = len(subset)\n",
        "    row_counts.append(count)  # Store the count\n",
        "    print(f\"Status {i}: {count} rows\")\n",
        "\n",
        "# Find the maximum value\n",
        "max_rows = max(row_counts)\n",
        "print(f\"The maximum number of rows is: {max_rows}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oEWzRXe7eGro",
      "metadata": {
        "id": "oEWzRXe7eGro"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Desired sample size for each group (e.g., equal-sized groups for balancing)\n",
        "desired_sample_size = max_rows  # Adjust based on your needs\n",
        "\n",
        "resampled_dfs = []\n",
        "\n",
        "for i in range(7):  # Status values from 0 to 6\n",
        "    subset = data[data['status'] == i]\n",
        "\n",
        "    # Resample each group\n",
        "    resampled_subset = resample(\n",
        "        subset,\n",
        "        replace=True if len(subset) < desired_sample_size else False,  # Use replacement if the group is small\n",
        "        n_samples=desired_sample_size,  # Resample to desired size\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    resampled_dfs.append(resampled_subset)\n",
        "\n",
        "# Combine resampled data\n",
        "data_new = pd.concat(resampled_dfs, axis=0).reset_index(drop=True)\n",
        "\n",
        "# Verify the new distribution\n",
        "print(data_new['status'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yg_F0auwOho2",
      "metadata": {
        "id": "yg_F0auwOho2"
      },
      "outputs": [],
      "source": [
        "x = data_new[\"stemmed_tokens\"]\n",
        "y = data_new[\"status\"]\n",
        "y.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5z3LctzEO-pj",
      "metadata": {
        "id": "5z3LctzEO-pj"
      },
      "outputs": [],
      "source": [
        "y_encode = to_categorical(y)\n",
        "y_encode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LNCrRw6CPBBd",
      "metadata": {
        "id": "LNCrRw6CPBBd"
      },
      "outputs": [],
      "source": [
        "x_train, x_temp, y_train, y_temp = train_test_split(x, y_encode, test_size=0.3, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)\n",
        "x_train.shape, x_val.shape, x_test.shape, y_train.shape, y_val.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cqnz6j4RmBo9",
      "metadata": {
        "id": "cqnz6j4RmBo9"
      },
      "outputs": [],
      "source": [
        "x.shape, x_temp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9Vx_Fxs2e_Km",
      "metadata": {
        "id": "9Vx_Fxs2e_Km"
      },
      "outputs": [],
      "source": [
        "tk = Tokenizer()\n",
        "tk.fit_on_texts(x_train)\n",
        "vocab_size = len(tk.index_word) + 1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eHKiV1RDwld",
      "metadata": {
        "id": "4eHKiV1RDwld"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Save the tokenizer used during training\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tk, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u93SwGJsfDcX",
      "metadata": {
        "id": "u93SwGJsfDcX"
      },
      "outputs": [],
      "source": [
        "x_train_number = tk.texts_to_sequences(x_train)\n",
        "x_val_number = tk.texts_to_sequences(x_val)\n",
        "x_test_number = tk.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xcY_eOcqtIh8",
      "metadata": {
        "id": "xcY_eOcqtIh8"
      },
      "outputs": [],
      "source": [
        "max_len = 100\n",
        "x_train_number = pad_sequences(x_train_number, maxlen=max_len, padding=\"post\")\n",
        "x_test_number = pad_sequences(x_test_number, maxlen=max_len, padding=\"post\")\n",
        "x_val_number = pad_sequences(x_val_number, maxlen=max_len, padding=\"post\")\n",
        "x_train_number.shape, x_val_number.shape, x_test_number.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3MfxWS02PPoJ",
      "metadata": {
        "id": "3MfxWS02PPoJ"
      },
      "source": [
        "***MULTI CHANNEL CNN MODEL***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UT_Zs478PKAg",
      "metadata": {
        "id": "UT_Zs478PKAg"
      },
      "outputs": [],
      "source": [
        "def multi_layer_model(vocab_size, max_length):\n",
        "    # 1st channel\n",
        "    inputs1 = Input(shape = (max_length,))\n",
        "    embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
        "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
        "    drop1 = Dropout(0.7)(conv1)\n",
        "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "    flat1 = Flatten()(pool1)\n",
        "\n",
        "    # 2nd channel\n",
        "    inputs2 = Input(shape = (max_length,))\n",
        "    embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
        "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
        "    drop2 = Dropout(0.7)(conv2)\n",
        "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "    flat2 = Flatten()(pool2)\n",
        "\n",
        "    # 3rd channel\n",
        "    inputs3 = Input(shape = (max_length,))\n",
        "    embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
        "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
        "    drop3 = Dropout(0.7)(conv3)\n",
        "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "    flat3 = Flatten()(pool3)\n",
        "\n",
        "\n",
        "    merged = concatenate([flat1, flat2, flat3])\n",
        "    outputs = Dense(7, activation='softmax')(merged)\n",
        "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tKsaF-LCRKmY",
      "metadata": {
        "id": "tKsaF-LCRKmY"
      },
      "outputs": [],
      "source": [
        "filepath=\"weights_best.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor= \"val_accuracy\" , verbose=1, save_best_only=True,mode= \"max\" )\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ks4B7acJRLNy",
      "metadata": {
        "id": "Ks4B7acJRLNy"
      },
      "outputs": [],
      "source": [
        "model = multi_layer_model(vocab_size=vocab_size, max_length=max_len)\n",
        "history = model.fit([x_train_number, x_train_number, x_train_number], y_train,\n",
        "                    validation_data=([x_val_number, x_val_number, x_val_number], y_val),\n",
        "                    epochs=10,\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89AlmMGcRNJz",
      "metadata": {
        "id": "89AlmMGcRNJz"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"weights_best.keras\")\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BzDmTrNWaHUN",
      "metadata": {
        "id": "BzDmTrNWaHUN"
      },
      "outputs": [],
      "source": [
        "_, acc = model.evaluate([x_train_number, x_train_number, x_train_number], y_train, verbose=0)\n",
        "print('Training Accuracy: %f' % (acc*100))\n",
        "# Validation Accuracy\n",
        "_, acc = model.evaluate([x_val_number, x_val_number, x_val_number], y_val, verbose=0)\n",
        "print('Validation Accuracy: %f' % (acc*100))\n",
        "# Test Accuracy\n",
        "_, acc = model.evaluate([x_test_number, x_test_number, x_test_number], y_test, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NsSNCaJeISh-",
      "metadata": {
        "id": "NsSNCaJeISh-"
      },
      "outputs": [],
      "source": [
        "pred = np.argmax(model.predict([x_test_number, x_test_number, x_test_number]), axis=1)\n",
        "pred = Lb.inverse_transform(pred)\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DGE8XyeZbJLW",
      "metadata": {
        "id": "DGE8XyeZbJLW"
      },
      "outputs": [],
      "source": [
        "history_df = pd.DataFrame()\n",
        "for key in history.history.keys():\n",
        "    history_df[key] = history.history[key]\n",
        "history_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hBdolTzVok2K",
      "metadata": {
        "id": "hBdolTzVok2K"
      },
      "outputs": [],
      "source": [
        "fig = px.line(\n",
        "    history_df,\n",
        "    x=history_df.index,\n",
        "    y=['loss', 'val_loss'],\n",
        "    title='Model Loss',\n",
        "    color_discrete_sequence=['green', 'orange']\n",
        ")\n",
        "fig.update_xaxes(title_text='Epochs')\n",
        "fig.update_yaxes(title_text='Loss')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k3HHIxekou_Q",
      "metadata": {
        "id": "k3HHIxekou_Q"
      },
      "outputs": [],
      "source": [
        "fig = px.line(\n",
        "    history_df,\n",
        "    x=history_df.index,\n",
        "    y=['accuracy', 'val_accuracy'],\n",
        "    title='Model Accuracy',\n",
        "    color_discrete_sequence=['green', 'orange']\n",
        ")\n",
        "fig.update_xaxes(title_text='Epochs')\n",
        "fig.update_yaxes(title_text='Accuracy')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iuC51vb9OVRL",
      "metadata": {
        "id": "iuC51vb9OVRL"
      },
      "source": [
        "***BERT TRANSFORMER WITH XGBOOST***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EToTQB3uO295",
      "metadata": {
        "id": "EToTQB3uO295"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "print(f\"Text input shape: {text_input.shape}, Text input dtype: {text_input.dtype}\")\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "embedding_model = tf.keras.Model(inputs=[text_input], outputs=[outputs['pooled_output']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TFmaTwGVPkKP",
      "metadata": {
        "id": "TFmaTwGVPkKP"
      },
      "outputs": [],
      "source": [
        "train_embeddings = embedding_model.predict(x_train)\n",
        "val_embeddings = embedding_model.predict(x_val)\n",
        "test_embeddings = embedding_model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jgwqes5PjImr",
      "metadata": {
        "id": "Jgwqes5PjImr"
      },
      "outputs": [],
      "source": [
        "# Define the model with parameters\n",
        "xgb = XGBClassifier(alpha=0.5, lambda_=1.0, learning_rate=0.05, n_estimators=500, early_stopping_rounds=10,eval_metric=\"logloss\")\n",
        "\n",
        "# Train the model and validate on validation set\n",
        "xgb.fit(train_embeddings, y_train, eval_set=[(train_embeddings,y_train),(val_embeddings,y_val)], verbose=True)\n",
        "\n",
        "# Get predictions\n",
        "y_train_pred = xgb.predict(train_embeddings)\n",
        "y_val_pred = xgb.predict(val_embeddings)\n",
        "y_test_pred = xgb.predict(test_embeddings)\n",
        "\n",
        "# Compute accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute log loss\n",
        "y_train_prob = xgb.predict_proba(train_embeddings)\n",
        "y_val_prob = xgb.predict_proba(val_embeddings)\n",
        "y_test_prob = xgb.predict_proba(test_embeddings)\n",
        "\n",
        "train_loss = log_loss(y_train, y_train_prob)\n",
        "val_loss = log_loss(y_val, y_val_prob)\n",
        "test_loss = log_loss(y_test, y_test_prob)\n",
        "\n",
        "# Display the results\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}, Training Loss: {train_loss:.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HrNzcBETLSRP",
      "metadata": {
        "id": "HrNzcBETLSRP"
      },
      "outputs": [],
      "source": [
        "# Save the trained XGBoost model\n",
        "with open('xgb_model.pkl', 'wb') as f:\n",
        "    pickle.dump(xgb, f)\n",
        "\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(Lb, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oZ2efCD9sGuZ",
      "metadata": {
        "id": "oZ2efCD9sGuZ"
      },
      "outputs": [],
      "source": [
        "evals_result = xgb.evals_result()\n",
        "# Extract the losses for training and validation datasets\n",
        "training_loss = evals_result['validation_0']['logloss']  # Training loss\n",
        "validation_loss = evals_result['validation_1']['logloss']  # Validation loss\n",
        "\n",
        "# Manually calculate accuracy per iteration for training and validation sets\n",
        "training_accuracy = []\n",
        "validation_accuracy = []\n",
        "epochs_to_evaluate = range(0, len(training_loss), 50)  # Sample every 50 epochs\n",
        "\n",
        "for epoch in epochs_to_evaluate:\n",
        "    # Predict probabilities at the current stage\n",
        "    y_train_pred_epoch = xgb.predict(train_embeddings, iteration_range=(0, epoch + 1))\n",
        "    y_val_pred_epoch = xgb.predict(val_embeddings, iteration_range=(0, epoch + 1))\n",
        "\n",
        "    # Calculate accuracy for the current epoch\n",
        "    train_acc = accuracy_score(y_train, y_train_pred_epoch)\n",
        "    val_acc = accuracy_score(y_val, y_val_pred_epoch)\n",
        "\n",
        "    training_accuracy.append(train_acc)\n",
        "    validation_accuracy.append(val_acc)\n",
        "\n",
        "# Plot Loss Graph\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(len(training_loss)), training_loss, label=\"Training Loss\", color=\"blue\")\n",
        "plt.plot(range(len(validation_loss)), validation_loss, label=\"Validation Loss\", color=\"orange\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Log Loss\")\n",
        "plt.title(\"Training and Validation Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_to_evaluate, training_accuracy, label=\"Training Accuracy\", color=\"green\")\n",
        "plt.plot(epochs_to_evaluate, validation_accuracy, label=\"Validation Accuracy\", color=\"red\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training and Validation Accuracy Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yIxryg6sL4Ir",
      "metadata": {
        "id": "yIxryg6sL4Ir"
      },
      "source": [
        "***LSTM Model***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TZMyRWd-L-2N",
      "metadata": {
        "id": "TZMyRWd-L-2N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.regularizers import l2\n",
        "num_classes = y_train.shape[1]\n",
        "# LSTM model with L2 regularization\n",
        "model_b = Sequential([\n",
        "    tf.keras.Input(shape=(max_len,)),\n",
        "    Embedding(input_dim=vocab_size, output_dim=128),\n",
        "    LSTM(units=32),\n",
        "    Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))  # L2 regularization\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_b.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping\n",
        "# early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, verbose=1, restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2nMBzI4zs34A",
      "metadata": {
        "id": "2nMBzI4zs34A"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "history_b = model_b.fit(x_train_number, y_train,\n",
        "                        epochs=20,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(x_val_number, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ABDGLSfwZxXS",
      "metadata": {
        "id": "ABDGLSfwZxXS"
      },
      "outputs": [],
      "source": [
        "# Evaluate model_b (LSTM with L2 Regularization)\n",
        "train_acc_b = model_b.evaluate(x_train_number, y_train, verbose=0)[1]\n",
        "val_acc_b = model_b.evaluate(x_val_number, y_val, verbose=0)[1]\n",
        "test_acc_b = model_b.evaluate(x_test_number, y_test, verbose=0)[1]\n",
        "\n",
        "print(\"Model B (LSTM with L2 Regularization):\")\n",
        "print(f\"  Training Accuracy: {train_acc_b*100:.2f}%\")\n",
        "print(f\"  Validation Accuracy: {val_acc_b*100:.2f}%\")\n",
        "print(f\"  Test Accuracy: {test_acc_b*100:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1Ah5ZyRbblBJ",
      "metadata": {
        "id": "1Ah5ZyRbblBJ"
      },
      "outputs": [],
      "source": [
        "# Function to display metrics\n",
        "def display_metrics(history):\n",
        "    n = len(history.history['loss'])\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    ax.plot(range(n), history.history['loss'], 'r', label='Training Loss')\n",
        "    ax.plot(range(n), history.history['val_loss'], 'b', label='Validation Loss')\n",
        "    ax.legend()\n",
        "    ax.set_title('Loss over epochs')\n",
        "\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    ax.plot(range(n), history.history['accuracy'], 'r', label='Training Accuracy')\n",
        "    ax.plot(range(n), history.history['val_accuracy'], 'b', label='Validation Accuracy')\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.set_title('Accuracy over epochs')\n",
        "\n",
        "display_metrics(history_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NYD-KuW18Msi",
      "metadata": {
        "id": "NYD-KuW18Msi"
      },
      "source": [
        "***User Input text Class Prediction***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tCEQ-B5Mk55t",
      "metadata": {
        "id": "tCEQ-B5Mk55t"
      },
      "outputs": [],
      "source": [
        "from ipywidgets import widgets, VBox, Label, Button, Dropdown\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load resources\n",
        "# Tokenizer\n",
        "with open('tokenizer.pkl', 'rb') as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "\n",
        "# Stopwords and stemmer\n",
        "stopwords_list = stopwords.words('english')\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# XGBoost model\n",
        "with open('xgb_model.pkl', 'rb') as f:\n",
        "    xgb_model = pickle.load(f)\n",
        "\n",
        "# BERT layers\n",
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
        "\n",
        "# BERT embedding model\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "embedding_model = tf.keras.Model(inputs=[text_input], outputs=[outputs['pooled_output']])\n",
        "\n",
        "# Function: Preprocess input text\n",
        "def preprocess_text(text):\n",
        "    tokens = text.split()\n",
        "    stemmed = [stemmer.stem(word) for word in tokens if word.lower() not in stopwords_list]\n",
        "    return ' '.join(stemmed)\n",
        "\n",
        "# Function: Generate BERT embeddings\n",
        "def get_embeddings(text):\n",
        "    return embedding_model.predict([text])\n",
        "\n",
        "# IPyWidgets components\n",
        "input_box = widgets.Text(\n",
        "    description=\"Text:\",\n",
        "    placeholder=\"Enter a sentence\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout={\"width\": \"600px\"}\n",
        ")\n",
        "\n",
        "model_selector = Dropdown(\n",
        "    options=[\"LSTM\", \"CNN\", \"BERT\"],\n",
        "    description=\"Model:\",\n",
        "    style={\"description_width\": \"initial\"},\n",
        "    layout={\"width\": \"300px\"}\n",
        ")\n",
        "\n",
        "output_label = widgets.Label(value=\"\")\n",
        "predict_button = Button(description=\"Predict\", button_style=\"success\")\n",
        "\n",
        "# Define the prediction logic\n",
        "def on_predict_clicked(b):\n",
        "    selected_model = model_selector.value\n",
        "    input_text = input_box.value.strip()\n",
        "\n",
        "    if not input_text:\n",
        "        output_label.value = \"Please enter a valid text.\"\n",
        "        return\n",
        "\n",
        "    # Preprocess input text\n",
        "    processed_text = preprocess_text(input_text)\n",
        "\n",
        "    if selected_model == \"LSTM\":\n",
        "        # LSTM Model: Single-channel input\n",
        "        input_sequence = tokenizer.texts_to_sequences([processed_text])\n",
        "        input_padded = pad_sequences(input_sequence, maxlen=max_len, padding='post')\n",
        "        input_multi_channel = [input_padded]\n",
        "        prediction = model_b.predict(input_multi_channel)\n",
        "        predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    elif selected_model == \"CNN\":\n",
        "        # CNN Model: Multi-channel input\n",
        "        input_sequence = tokenizer.texts_to_sequences([processed_text])\n",
        "        input_padded = pad_sequences(input_sequence, maxlen=max_len, padding='post')\n",
        "        input_multi_channel = [input_padded, input_padded, input_padded]\n",
        "        prediction = model.predict(input_multi_channel)  # Replace 'model' with the CNN model variable\n",
        "        predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    elif selected_model == \"BERT\":\n",
        "        # BERT Model: Generate embeddings and predict with XGBoost\n",
        "        bert_embedding = get_embeddings(input_text)\n",
        "        prediction = xgb_model.predict_proba(bert_embedding)\n",
        "        predicted_index = np.argmax(prediction, axis=1)\n",
        "\n",
        "    # Map index to category name\n",
        "    predicted_category = Lb.inverse_transform(predicted_index)  # Replace 'Lb' with the LabelEncoder object\n",
        "    output_label.value = f\"Predicted Category: {predicted_category[0]}\"\n",
        "\n",
        "# Reset output when the user types new text or changes the model\n",
        "def on_input_change(change):\n",
        "    output_label.value = \"\"  # Clear the output\n",
        "\n",
        "# Attach event handlers\n",
        "predict_button.on_click(on_predict_clicked)\n",
        "input_box.observe(on_input_change, names=\"value\")\n",
        "model_selector.observe(on_input_change, names=\"value\")\n",
        "\n",
        "# Display the interface\n",
        "display(VBox([\n",
        "    Label(\"Mental Health Text Classification\"),\n",
        "    model_selector,\n",
        "    input_box,\n",
        "    predict_button,\n",
        "    output_label\n",
        "]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1hdyRR1uHGxs",
      "metadata": {
        "id": "1hdyRR1uHGxs"
      },
      "source": [
        "***Cross Validation***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "I5QWI-0FHFcI",
      "metadata": {
        "id": "I5QWI-0FHFcI"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Assume your data is loaded and preprocessed as x_data and y_data\n",
        "x_data = x_train_number  # Your input data\n",
        "y_data = y_train  # Your labels\n",
        "print(f\"x_data size: {len(x_data)}, y_data size: {len(y_data)}\")\n",
        "\n",
        "k = 5  # Number of folds for cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Lists to store the performance metrics\n",
        "cnn_accuracies = []\n",
        "lstm_accuracies = []\n",
        "\n",
        "fold_number = 1\n",
        "# Loop through each fold\n",
        "for train_index, val_index in kf.split(x_data):\n",
        "    print(f\"Running Fold {fold_number}...\")\n",
        "    # Split the data into training and validation sets for this fold\n",
        "    x_train, x_val = x_data[train_index], x_data[val_index]\n",
        "    y_train, y_val = y_data[train_index], y_data[val_index]\n",
        "\n",
        "    # ----- Multi-Channel CNN Model -----\n",
        "    cnn_model = multi_layer_model(vocab_size=vocab_size, max_length=max_len)  # Adjust with your parameters\n",
        "    cnn_model.fit([x_train, x_train, x_train], y_train, epochs=5, verbose=0)\n",
        "    _, cnn_acc = cnn_model.evaluate([x_val, x_val, x_val], y_val, verbose=0)\n",
        "    cnn_accuracies.append(cnn_acc)\n",
        "    print(f\"Fold {fold_number} - CNN Accuracy: {cnn_acc * 100:.2f}%\")\n",
        "\n",
        "    # ----- LSTM Model -----\n",
        "    lstm_model = model_b\n",
        "\n",
        "    # Compile the model\n",
        "    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Early stopping\n",
        "    early_stopping = EarlyStopping(monitor='accuracy', patience=3, verbose=1, restore_best_weights=True)\n",
        "\n",
        "    lstm_model.fit(x_train, y_train, epochs=10, verbose=0, callbacks=[early_stopping])\n",
        "    _, lstm_acc = lstm_model.evaluate(x_val, y_val, verbose=0)\n",
        "    lstm_accuracies.append(lstm_acc)\n",
        "    print(f\"Fold {fold_number} - LSTM Accuracy: {lstm_acc * 100:.2f}%\")\n",
        "\n",
        "    fold_number += 1\n",
        "\n",
        "# Calculate average performance metrics\n",
        "avg_cnn_accuracy = np.mean(cnn_accuracies)\n",
        "avg_lstm_accuracy = np.mean(lstm_accuracies)\n",
        "\n",
        "print(f\"Average CNN Accuracy: {avg_cnn_accuracy * 100:.2f}%\")\n",
        "print(f\"Average LSTM Accuracy: {avg_lstm_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57d623a1",
      "metadata": {
        "id": "57d623a1"
      },
      "source": [
        "***Hypothesis Testing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c1c26c",
      "metadata": {
        "id": "27c1c26c"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Perform a paired t-test\n",
        "t_stat, p_value = ttest_rel(cnn_accuracies, lstm_accuracies)\n",
        "\n",
        "print(\"\\nHypothesis Testing Results:\")\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Interpret the results\n",
        "alpha = 0.05  # Significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the models.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the models.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}